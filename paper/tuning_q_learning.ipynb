{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import random\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.path import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "import networkx as nx\n",
    "import winsound\n",
    "import time\n",
    "import pandas as pd\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "warnings.simplefilter(\"error\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1e3\n",
    "P = 1e3\n",
    "L = 1e3\n",
    "r = 250\n",
    "d_max = 500\n",
    "BS = [P/2, L/2, -D/2]\n",
    "\n",
    "f = 4e4\n",
    "pH = 7.82      \n",
    "sh = 0.8\n",
    "T = 4.11\n",
    "S = 34.31\n",
    "w = 6\n",
    "k = 1.5\n",
    "spreading_factor = 2\n",
    "m = 10\n",
    "bernoulli_probability = 0.95\n",
    "\n",
    "d = r*np.sqrt(3)\n",
    "N_l = np.ceil((((P-d)/d) + 1))\n",
    "N_h = np.ceil(((2*np.sqrt(3)*L-6*d+4*np.sqrt(3)*r)/(3*d)) + 1)\n",
    "N_total = N_h * N_l\n",
    "numLayer = -int(D/r)\n",
    "N = N_total * -numLayer\n",
    "print(N)\n",
    "\n",
    "kc = 25\n",
    "kd = 250\n",
    "kt = kd + N\n",
    "beta = 0.8\n",
    "data_rate = 500 # bps\n",
    "t_transmission =  ((kd * 8)/data_rate) + ((kc * 8)/data_rate) + (((kc + N) * 8)/data_rate)\n",
    "initial_energy = 500\n",
    "P_tx = 2\n",
    "P_rx = 0.5\n",
    "P_idle = 2 * 1e-3\n",
    "\n",
    "T_c = ((kc * 8)/data_rate)\n",
    "T_d = ((kd * 8)/data_rate)\n",
    "T_t = (((kc + N) * 8)/data_rate)\n",
    "\n",
    "DECKS_threshold = 3\n",
    "p = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vibrationFrequencies(show_info = False):\n",
    "    f1 = 0.78 * np.sqrt(S/35) * np.exp(T/26)\n",
    "    f2 = 42 * np.exp(T/17)\n",
    "\n",
    "    if show_info: \n",
    "        print(f\"F1 : {f1:.2f} | f2 : {f2:.2f}\")\n",
    "\n",
    "    return f1, f2\n",
    "\n",
    "f1, f2 = vibrationFrequencies(show_info = False)\n",
    "def attenuationConstant(D, show_info = False):\n",
    "    D_km = D/1e3\n",
    "    f1_kHz = f1/1e3\n",
    "    f2_kHz = f2/1e3\n",
    "    f_kHz = f/1e3\n",
    "\n",
    "    term1 = 0.106 * (f1_kHz * f_kHz**2) / (f1_kHz**2 + f_kHz**2) * np.exp((pH - S) / 0.56)\n",
    "    term2 = 0.52 * (1 + (T / 43)) * (S / 35) * (f2_kHz * f_kHz**2) / (f2_kHz**2 + f_kHz**2) * np.exp(-D_km / 0.56)\n",
    "    term3 = 4.9e-4 * f2 * np.exp(T / 27 + D_km / 17)\n",
    "    attenuation = term1 + term2 + term3\n",
    "    if show_info: \n",
    "        print(f\"attenuation constant: {attenuation:.2f}\")\n",
    "\n",
    "    return attenuation\n",
    "\n",
    "def attenuation_dB(distance, show_info = False):\n",
    "    distance = distance/1e3\n",
    "    att = k * np.log10(distance) + distance * attenuationConstant(show_info = True) * 1e-3\n",
    "    if show_info:   \n",
    "        print(f\"Attenuation at distance ({distance:.2f} m) : {att:.2f} dB\")\n",
    "    return att\n",
    "\n",
    "def attenuation(D, distance, show_info = False):\n",
    "    distance = distance/1e3\n",
    "    att = (distance**spreading_factor) * (attenuationConstant(D, show_info = False)**distance)\n",
    "    if show_info:   \n",
    "        print(f\"Attenuation at distance ({distance:.2f} m) | Att {att:.2f} | Att constant : {attenuationConstant(D, show_info = False)}\")\n",
    "        print(f\"Attenuation at distance ({distance:.2f} m) : {att:.2f} dB\")\n",
    "    return att\n",
    "\n",
    "def noise(show_info = False):\n",
    "    f_khz = f / 1e3\n",
    "    turbulence_noise    = 17 - 30 * np.log10(f_khz)\n",
    "    ship_noise          = 40 + 20 * (sh - 0.5) + 26 * np.log10(f_khz) - 60 * np.log10(f_khz + 0.03)\n",
    "    wind_noise          =  50 + 7.5 * np.sqrt(w) + 20 * np.log10(f_khz) - 40 * np.log10(f_khz + 0.4)\n",
    "    thermal_noise       =  -15 + 20 * np.log10(f_khz)\n",
    "\n",
    "    noise_total = turbulence_noise + ship_noise + wind_noise + thermal_noise\n",
    "\n",
    "    if show_info:   \n",
    "        turbulence_noise    = round(turbulence_noise    , 2)\n",
    "        ship_noise          = round(ship_noise          , 2)\n",
    "        wind_noise          = round(wind_noise          , 2)\n",
    "        thermal_noise       = round(thermal_noise       , 2)\n",
    "        noise_total         = round(noise_total       , 2)\n",
    "        print(f\"Noise total : {noise_total} | Thermal noise : {thermal_noise} | Ship noise : {ship_noise} | Wind noise : {wind_noise} | Turbulence noise : {turbulence_noise} | f : {f_khz} kHz\")\n",
    "    return noise_total\n",
    "\n",
    "def underwater_speed(D, show_info = False):\n",
    "    D_km = D/1e3\n",
    "    v_uw = 1448.96 + 4.591 * T - 5.304e-2 * T**2 + 2.374 * T**3 + 1.340 * (S - 35) + \\\n",
    "           1.630e-2 * D_km + 1.675e-7 * D_km**2 - 1.025e-2 * T * (S - 35) - 7.139e-13 * D_km**3 * T\n",
    "    \n",
    "    if show_info:\n",
    "        print(f\"Underwater speed at D = {D:.2f} is : {v_uw:.2f} m/s\")\n",
    "\n",
    "    return v_uw\n",
    "\n",
    "def ratio_delay(D, distance):\n",
    "    v_uw = underwater_speed(D, show_info = False)\n",
    "    t_uw = distance/v_uw\n",
    "    a = t_uw/t_transmission\n",
    "    # print(f\"Ratio delay : {a:.2f} | T_tranmission : {t_transmission:.2f} | T_uw : {t_uw:.2f}\")\n",
    "    return a\n",
    "\n",
    "def throughput(a):\n",
    "    numerator = kc * np.exp(-a * kc)\n",
    "    denominator = kc * (1 + 2 * a) + np.exp(-a * kc)\n",
    "    rho = numerator / denominator\n",
    "    # print(f\"Throughput : {rho:.2f} | numerator : {numerator:.2f} | denominator : {denominator:.2f}\")\n",
    "    return rho\n",
    "\n",
    "def generate_sound(frequency, duration, sample_rate=44100):\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "    audio = np.sin(2 * np.pi * frequency * t)\n",
    "    return audio\n",
    "\n",
    "def play_sound(duration):\n",
    "    winsound.Beep(440, int(duration/6 * 1000))  # winsound.Beep takes frequency in Hz and duration in milliseconds\n",
    "    winsound.Beep(880, int(duration/6 * 1000))  # winsound.Beep takes frequency in Hz and duration in milliseconds\n",
    "    winsound.Beep(440, int(duration/6 * 1000))  # winsound.Beep takes frequency in Hz and duration in milliseconds\n",
    "    winsound.Beep(880, int(duration/6 * 1000))  # winsound.Beep takes frequency in Hz and duration in milliseconds\n",
    "    winsound.Beep(440, int(duration/6 * 1000))  # winsound.Beep takes frequency in Hz and duration in milliseconds\n",
    "    winsound.Beep(880, int(duration/6 * 1000))  # winsound.Beep takes frequency in Hz and duration in milliseconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bernoulli():\n",
    "    def pmf(x,p):\n",
    "        f = p**x*(1-p)**(1-x)\n",
    "        return f\n",
    "    \n",
    "    def mean(p):\n",
    "        return p\n",
    "    \n",
    "    def var(p):\n",
    "        return p*(1-p)\n",
    "    \n",
    "    def std(p):\n",
    "        return bernoulli.var(p)**(1/2)\n",
    "    \n",
    "    def rvs(p,size=1):\n",
    "        rvs = np.array([])\n",
    "        for i in range(0,size):\n",
    "            if np.random.rand() <= p:\n",
    "                a=1\n",
    "                rvs = np.append(rvs,a)\n",
    "            else:\n",
    "                a=0\n",
    "                rvs = np.append(rvs,a)\n",
    "        return rvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, x, y, z, id):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.energy = initial_energy\n",
    "        self.nϵG = False\n",
    "        self.alive = True\n",
    "        self.CH = False\n",
    "        self.which_cluster = 0\n",
    "        self.eligible_round = 0\n",
    "        self.cluster_class = 0\n",
    "        self.id = id\n",
    "        self.has_data = True\n",
    "\n",
    "    def distance(self, other_node):\n",
    "        return np.sqrt((self.x - other_node.x)**2 + (self.y - other_node.y)**2 + (self.z - other_node.z)**2)\n",
    "\n",
    "    def reset(self):\n",
    "        self.CH = False\n",
    "        self.which_cluster = 0\n",
    "        self.has_data = True\n",
    "\n",
    "    def advertisement(self, count_cluster, eligible_round):\n",
    "        self.CH = True\n",
    "        self.nϵG = False\n",
    "        self.eligible_round = eligible_round\n",
    "        self.which_cluster = count_cluster\n",
    "    \n",
    "    def energyIdle(self):\n",
    "        return P_idle \n",
    "\n",
    "    def energySelection(self, d_CH_BS, p):\n",
    "        # If node selected as a CH\n",
    "        a = ratio_delay(self.z, d_CH_BS)\n",
    "        rho = throughput(a)\n",
    "        first_term = (T_c / rho) * P_tx * attenuation(self.z, d_CH_BS, show_info = False)\n",
    "        second_term = ((p * N - 1) / rho) * T_c * self.energyIdle()\n",
    "        third_term = T_t * P_rx\n",
    "        E_Selection = first_term + second_term + third_term\n",
    "        return E_Selection\n",
    "\n",
    "    def energyAdvertisement(self):\n",
    "        # Broadcasting to all nodes in the range of d_max, occurs only for CH\n",
    "        return T_c * P_tx * attenuation(self.z, d_max, show_info = False)\n",
    "    \n",
    "    def energyJoin(self, p):\n",
    "        # Node receive the broadcasting message and decide whether want to join as a associated node for CH i-th\n",
    "        return p * N * T_c * P_rx\n",
    "\n",
    "    def energy_contention_TDMA_CH(self, Nc):\n",
    "        return (T_c * Nc * P_rx ) + (T_c * P_tx * attenuation(self.z, d_max, show_info = False))\n",
    "    \n",
    "    def energy_contention_TDMA_Node(self, Nc, d_CH_Node):\n",
    "        a = ratio_delay(self.z, d_CH_Node)\n",
    "        rho = throughput(a)\n",
    "        energy = (T_c / rho) * (P_tx * attenuation(self.z, d_CH_Node, show_info = False)) + ((Nc-1)/ rho) * T_c * self.energyIdle() + T_t * P_rx\n",
    "        # print(energy)\n",
    "        return energy\n",
    "    \n",
    "    def energyFrame_CH(self, Nc, d_CH_BS):\n",
    "        return (m * Nc * T_d * P_rx) + ((N-Nc) * self.energyIdle() * T_d) + T_d * (P_tx * attenuation(self.z, d_CH_BS, show_info = False))\n",
    "    \n",
    "    def energyFrame_Node(self, d_CH_Node):\n",
    "        return m * T_d * ( P_tx * attenuation(self.z, d_CH_Node, show_info = False))\n",
    "    \n",
    "    def energyHop(self, d_CH_Node):\n",
    "        return T_d * ( P_tx * attenuation(self.z, d_CH_Node, show_info = False))\n",
    "    \n",
    "    \n",
    "\n",
    "def triangulation3D(show_info=False):\n",
    "    d = r*np.sqrt(3)\n",
    "    N_l = np.ceil((((P-d)/d) + 1))\n",
    "    N_h = np.ceil(((2*np.sqrt(3)*L-6*d+4*np.sqrt(3)*r)/(3*d)) + 1)\n",
    "    N_total = N_h * N_l\n",
    "    dy = np.power(d, 2) - np.power(d/2, 2)\n",
    "    dy = np.sqrt(dy)\n",
    "    dh = ((np.sqrt(3)/2) * d) - r\n",
    "    dl = d/2\n",
    "    numLayer = -int(D/r)\n",
    "    \n",
    "    sensor_pos = {'x' : [], 'y':[], 'z':[]}\n",
    "    sensor_coverage = []\n",
    "\n",
    "    for z in range(numLayer, 0, 1):\n",
    "         for x in range(0, int(N_l)):\n",
    "            for y in range(0, int(N_h)):\n",
    "                if y % 2 != 0:\n",
    "                    # Odd\n",
    "                    x_p = (d * x) \n",
    "                    y_p = dy * y\n",
    "                    z_p = z * r\n",
    "                    sensor_pos['x'].append(x_p)\n",
    "                    sensor_pos['y'].append(y_p)\n",
    "                    sensor_pos['z'].append(z_p)\n",
    "                    sensor_coverage.append((x_p, y_p))\n",
    "                else:\n",
    "                    x_p = (d * x) + (d/2)\n",
    "                    y_p = dy * y\n",
    "                    z_p = z * r\n",
    "                    sensor_pos['x'].append(x_p)\n",
    "                    sensor_pos['y'].append(y_p)\n",
    "                    sensor_pos['z'].append(z_p)\n",
    "                    sensor_coverage.append((x_p, y_p))\n",
    "\n",
    "    if show_info: \n",
    "        print(f\"N_i : {N_l} | N_h : {N_h} | N_total : {N_total * -numLayer:.2f} | Num layer : {-numLayer} | d/r : {d/r:.2f} | r : {r:.2f} | d : {d:.2f} | dy : {dy:.2f} | dl : {dl:.2f} | dh : {dh:.2f}\")\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(sensor_pos['x'], sensor_pos['y'], sensor_pos['z'], marker=\"o\",color='r', edgecolors='k')\n",
    "        ax.scatter(BS[0], BS[1], BS[2], marker=\"s\",color='b', edgecolors='k')\n",
    " \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(int(P//5)))\n",
    "        ax.yaxis.set_major_formatter('{x:.0f}')\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(int(P//10)))\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(int(L//5)))\n",
    "        ax.xaxis.set_major_formatter('{x:.0f}')\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(int(L//10)))\n",
    "        ax.scatter(sensor_pos['x'], sensor_pos['y'], color='r', edgecolors=None, facecolors='None')\n",
    "        verts = [\n",
    "        (0., 0.),  # left, bottom\n",
    "        (0., P),  # left, top\n",
    "        (L, P),  # right, top\n",
    "        (L, 0.),  # right, bottom\n",
    "        (0., 0.),  # ignored\n",
    "        ]\n",
    "\n",
    "        codes = [\n",
    "            Path.MOVETO,\n",
    "            Path.LINETO,\n",
    "            Path.LINETO,\n",
    "            Path.LINETO,\n",
    "            Path.CLOSEPOLY,\n",
    "        ]\n",
    "\n",
    "        path = Path(verts, codes)\n",
    "\n",
    "        rect = patches.PathPatch(path, facecolor='none', lw=0.5, linestyle='--')\n",
    "        ax.add_patch(rect)\n",
    "        for cov in sensor_coverage:\n",
    "            circle = plt.Circle(cov, r, color='k', fill=False, linewidth=0.5, linestyle='--')\n",
    "            ax.add_patch(circle)\n",
    "        ax.set_xlabel('Length (m)')\n",
    "        ax.set_ylabel('Width (m)')\n",
    "        plt.axis('equal')\n",
    "    return sensor_pos\n",
    "\n",
    "def createNetworks():\n",
    "    sensor_pos = triangulation3D(show_info=False)\n",
    "    nodes = []\n",
    "    nodes.append(Node(BS[0], BS[1], BS[2], 0))\n",
    "    nodes[0].energy = 0.1\n",
    "    for i in range(0, len(sensor_pos['x'])):\n",
    "        nodes.append(\n",
    "            Node(sensor_pos['x'][i], sensor_pos['y'][i],  sensor_pos['z'][i], i + 1)\n",
    "        )\n",
    "        # print(f\"id : {i + 1}\")\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def createNetworksRandom():\n",
    "    areaTotal = P * L * D\n",
    "\n",
    "    #Point process parameters\n",
    "    lambda0 = N/(P * D * L)\n",
    "\n",
    "    #Simulate a Poisson point process\n",
    "    numbPoints = np.random.poisson(lambda0 * areaTotal)\n",
    "    \n",
    "    xx = P  * np.random.uniform(0,1, int(N))\n",
    "    yy = L  * np.random.uniform(0,1, int(N))\n",
    "    zz = -D * np.random.uniform(0,1, int(N))\n",
    "\n",
    "    nodes = []\n",
    "    nodes.append(Node(BS[0], BS[1], BS[2], 0))\n",
    "    nodes[0].energy = 0.1\n",
    "\n",
    "    for i in range(len(xx)):\n",
    "        nodes.append(\n",
    "            Node(xx[i], yy[i], zz[i], i + 1)\n",
    "        )\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def standardize_features(feature1, feature2):\n",
    "    # Check if the input features are not empty\n",
    "    if not feature1 or not feature2:\n",
    "        raise ValueError(\"Input features are empty.\")\n",
    "\n",
    "    # Combine the features into a 2D array\n",
    "    features = np.column_stack((feature1, feature2))\n",
    "\n",
    "    # Check if the combined features array is not empty\n",
    "    if not features.any():\n",
    "        raise ValueError(\"Combined features array is empty.\")\n",
    "\n",
    "    # Create a StandardScaler instance\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the features and transform them\n",
    "    standardized_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Extract the standardized features back into separate arrays\n",
    "    standardized_feature1 = standardized_features[:, 0]\n",
    "    standardized_feature2 = standardized_features[:, 1]\n",
    "\n",
    "    return standardized_feature1, standardized_feature2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiHop(object):\n",
    "    def __init__(self,graph):\n",
    "        self.graph = graph\n",
    "        self.adjacent_mat = nx.adjacency_matrix(graph).todense()\n",
    "        self.num_nodes = len(self.adjacent_mat)\n",
    "        # self.adjacent_mat = nx.adjacency_matrix(graph, nodelist=range(self.num_nodes)).toarray()#:D\n",
    "        self.adjacent_mat = nx.adjacency_matrix(graph).toarray()\n",
    "\n",
    "    def q_learning(self,start_state=0, aim_state = 10, num_epoch=200, gamma=0.8, epsilon=0.05, alpha=0.1):\n",
    "        rewards = self.adjacent_mat.copy()\n",
    "        q_table = np.full((self.num_nodes, self.num_nodes), 100)  # Initialize Q-table with 100\n",
    "        td = []\n",
    "        for episode in range(1, num_epoch + 1):\n",
    "            count = 0\n",
    "            #print(f\"========================================================================== Episode : {episode} =========================================================================\")\n",
    "            current_state = start_state\n",
    "\n",
    "            while True:\n",
    "                if current_state >= self.num_nodes or current_state < 0:\n",
    "                    break  # Exit loop if current_state is out of bounds\n",
    "            \n",
    "                next_state = self.epsilon_greedy(current_state, q_table, start_state, aim_state, epsilon=epsilon)\n",
    "                \n",
    "                if next_state >= self.num_nodes or next_state < 0:\n",
    "                    break\n",
    "                reward = rewards[current_state][next_state]\n",
    "                delta = reward + gamma * np.min(q_table[next_state]) - q_table[current_state, next_state]\n",
    "\n",
    "                q_table[current_state, next_state] = q_table[current_state, next_state] + alpha * delta\n",
    "                q_table[current_state, next_state] = round(q_table[current_state, next_state], 5)\n",
    "                # update current state\n",
    "                current_state = next_state\n",
    "                td.append(delta)\n",
    "                count += 1\n",
    "                if ((current_state == aim_state) or (count > 100)):\n",
    "                    break\n",
    "                # print(f\"\\t\\tstart state : {start_state} | episode : {episode} | count : {count}\")\n",
    "            # print(f\"start state : {start_state} | episode : {episode} | count : {count}\")\n",
    "\n",
    "        shortest_path = self.calculate_shortest_path(q_table, start_state, aim_state)\n",
    "        return shortest_path, td\n",
    "\n",
    "    def calculate_shortest_path(self, q_table, start_state, aim_state):\n",
    "        current_state = start_state\n",
    "        shortest_path = [current_state]\n",
    "        max_iterations = self.num_nodes  # Setting a maximum number of iterations to avoid infinite loops\n",
    "\n",
    "        while current_state != aim_state and max_iterations > 0:\n",
    "            # Boundary check for current_state\n",
    "            if current_state >= self.num_nodes or current_state < 0:\n",
    "                shortest_path = [start_state]\n",
    "                print(f\"Unreachable {start_state} => {shortest_path}\")\n",
    "                return shortest_path  # Exit if current_state is out of bounds\n",
    "            \n",
    "            next_state = np.argmin(q_table[current_state])\n",
    "            \n",
    "            # Boundary check for next_state\n",
    "            if next_state >= self.num_nodes or next_state < 0:\n",
    "                shortest_path = [start_state]\n",
    "                print(f\"Unreachable {start_state} => {shortest_path}\")\n",
    "                return shortest_path  # Exit if next_state is out of bounds\n",
    "            \n",
    "            shortest_path.append(next_state)\n",
    "            current_state = next_state\n",
    "            max_iterations -= 1\n",
    "\n",
    "        if max_iterations <= 0:\n",
    "            shortest_path = [start_state]\n",
    "            print(f\"Unreachable {start_state} => {shortest_path}\")\n",
    "            # Handle this situation accordingly, such as returning None or an empty path\n",
    "        \n",
    "        return shortest_path\n",
    "        \n",
    "    def epsilon_greedy(self,s_curr, q, start_state, aim_state, epsilon):\n",
    "        if s_curr >= self.num_nodes or s_curr < 0:\n",
    "            return aim_state\n",
    "        potential_next_states = np.where(np.array(self.adjacent_mat[s_curr]) <= d_max)[0]\n",
    "        potential_next_states = potential_next_states[potential_next_states != start_state]\n",
    "        # print(f\"potential_next_states : {potential_next_states}\")\n",
    "        if len(potential_next_states) != 0:\n",
    "            if random.random() > epsilon:\n",
    "                q_of_next_states = q[s_curr][potential_next_states]\n",
    "                s_next = potential_next_states[np.argmin(q_of_next_states)]\n",
    "            else:\n",
    "                s_next = random.choice(potential_next_states)\n",
    "            return s_next\n",
    "        else:\n",
    "            # print(\"potential_next_states = 0\")\n",
    "            return aim_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class networkEnvironment:\n",
    "    def __init__(self, nodes, mode, showInfo, showPlotIteration, QL_params):\n",
    "        self.QL_params = QL_params\n",
    "        self.nodes = nodes \n",
    "        self.mode = mode\n",
    "        self.alive_data = []\n",
    "        self.energy_data = []\n",
    "        self.node_failure = []\n",
    "        self.total_packet_sent = []\n",
    "        self.PDR = []\n",
    "        self.data_sent = 0\n",
    "        self.centroids = np.array([[P//2, L//2, 0]])\n",
    "        self.showInfo = showInfo\n",
    "        self.showPlotIteration = showPlotIteration\n",
    "        self.multihop_path = []\n",
    "        self.optimal_k = 0\n",
    "        self.setupPhaseEnergy = []\n",
    "        self.steadyPhaseEnergy = []\n",
    "        self.show_path = []\n",
    "    \n",
    "    def showResult(self, hop):\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(20,5))\n",
    "        rounds = np.array([i for i in range(0, len(self.alive_data))])\n",
    "        self.alive_data = np.array(self.alive_data)\n",
    "        self.energy_data = np.array(self.energy_data)\n",
    "        self.node_failure = np.array(self.node_failure)\n",
    "\n",
    "        ax[0].plot(rounds, self.alive_data, color='k')\n",
    "        ax[0].scatter(rounds[::hop], self.alive_data[::hop], marker='o', edgecolor='k', color='r')\n",
    "        ax[0].set_ylabel(\"Node Alive\")\n",
    "        ax[0].set_xlabel(\"Round\")\n",
    "\n",
    "        ax[1].plot(rounds, self.energy_data, color='k')\n",
    "        ax[1].scatter(rounds[::hop], self.energy_data[::hop], marker='o', edgecolor='k', color='r')\n",
    "        ax[1].set_ylabel(\"Energy Consumed\")\n",
    "        ax[1].set_xlabel(\"Round\")\n",
    "\n",
    "        ax[2].plot(rounds[::hop], self.node_failure[::hop], color='k')\n",
    "        ax[2].scatter(rounds[::hop], self.node_failure[::hop], marker='o', edgecolor='k', color='r')\n",
    "        ax[2].set_ylabel(\"Node Failure\")\n",
    "        ax[2].set_xlabel(\"Round\")\n",
    "\n",
    "        ax[3].plot(rounds, self.PDR, color='k')\n",
    "        ax[3].scatter(rounds[::hop], self.PDR[::hop], marker='o', edgecolor='k', color='r')\n",
    "        ax[3].set_ylabel(\"Node Failure\")\n",
    "        ax[3].set_xlabel(\"Round\")\n",
    "\n",
    "        # ax[0].yaxis.set_major_locator(MultipleLocator(np.abs(np.max(self.alive_data))/20))\n",
    "        # ax[0].yaxis.set_major_formatter('{x:.2f}')\n",
    "        # ax[0].yaxis.set_minor_locator(MultipleLocator(np.abs(np.max(self.alive_data))/30))\n",
    "        # ax[0].xaxis.set_major_locator(MultipleLocator(np.max(rounds)/5))\n",
    "        # ax[0].xaxis.set_major_formatter('{x:.2f}')\n",
    "        # ax[0].xaxis.set_minor_locator(MultipleLocator(np.max(rounds)/10))\n",
    "        \n",
    "        # ax[1].yaxis.set_major_locator(MultipleLocator(np.abs(np.max(self.energy_data))/20))\n",
    "        # ax[1].yaxis.set_major_formatter('{x:.2f}')\n",
    "        # ax[1].yaxis.set_minor_locator(MultipleLocator(np.abs(np.max(self.energy_data))/30))\n",
    "        # ax[1].xaxis.set_major_locator(MultipleLocator(np.max(rounds)/5))\n",
    "        # ax[1].xaxis.set_major_formatter('{x:.2f}')\n",
    "        # ax[1].xaxis.set_minor_locator(MultipleLocator(np.max(rounds)/10))\n",
    "\n",
    "        # ax[2].yaxis.set_major_locator(MultipleLocator(np.abs(np.max(self.node_failure))/10))\n",
    "        # ax[2].yaxis.set_major_formatter('{x:.2f}')\n",
    "        # ax[2].yaxis.set_minor_locator(MultipleLocator(np.abs(np.max(self.node_failure))/20))\n",
    "        # ax[2].xaxis.set_major_locator(MultipleLocator(np.max(rounds)/5))\n",
    "        # ax[2].xaxis.set_major_formatter('{x:.2f}')\n",
    "        # ax[2].xaxis.set_minor_locator(MultipleLocator(np.max(rounds)/10))\n",
    "\n",
    "\n",
    "    def showNetwork(self, simulation_round):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        normal_nodes = {'x':[], 'y':[], 'z':[]}\n",
    "        orphan_nodes = {'x':[], 'y':[], 'z':[]}\n",
    "        CH_nodes = {'x':[], 'y':[], 'z':[]}\n",
    "        BS_node = {'x':[], 'y':[], 'z':[]}\n",
    "        dead_nodes = {'x':[], 'y':[], 'z':[]}\n",
    "        idle_nodes = {'x':[], 'y':[], 'z':[]}\n",
    "        energy = 0\n",
    "        node_alive = 0\n",
    "        count_CH = 0\n",
    "\n",
    "        for node in self.nodes:\n",
    "            normal_node_status = ((node.id != 0) and (node.CH == False) and (node.which_cluster != 0) and (node.energy > 0) and (node.has_data))\n",
    "            orphan_node_status = ((node.id != 0) and (node.CH == False) and (node.energy > 0) and (node.has_data))\n",
    "            idle_node_status = ((node.id != 0) and (node.CH == False) and (node.which_cluster == 0) and (node.energy > 0) and (node.has_data == False))\n",
    "            CH_node_status = ((node.id != 0) and (node.CH == True) and (node.alive) and (node.energy > 0))\n",
    "            dead_node_status = ((node.id != 0) and (node.energy < 0) and (node.alive != True))\n",
    "            \n",
    "            if normal_node_status:\n",
    "                normal_nodes['x'].append(node.x)\n",
    "                normal_nodes['y'].append(node.y)\n",
    "                normal_nodes['z'].append(node.z)\n",
    "            if orphan_node_status:\n",
    "                orphan_nodes['x'].append(node.x)\n",
    "                orphan_nodes['y'].append(node.y)\n",
    "                orphan_nodes['z'].append(node.z)\n",
    "            if CH_node_status:\n",
    "                CH_nodes['x'].append(node.x)\n",
    "                CH_nodes['y'].append(node.y)\n",
    "                CH_nodes['z'].append(node.z)\n",
    "                count_CH += 1\n",
    "            if node.id == 0:\n",
    "                BS_node['x'].append(node.x)\n",
    "                BS_node['y'].append(node.y)\n",
    "                BS_node['z'].append(node.z)\n",
    "            if idle_node_status:\n",
    "                idle_nodes['x'].append(node.x)\n",
    "                idle_nodes['y'].append(node.y)\n",
    "                idle_nodes['z'].append(node.z)\n",
    "            if dead_node_status:\n",
    "                dead_nodes['x'].append(node.x)\n",
    "                dead_nodes['y'].append(node.y)\n",
    "                dead_nodes['z'].append(node.z)\n",
    "            if node.alive:\n",
    "                energy += node.energy\n",
    "                node_alive += 1  \n",
    "            # ax.text(node.x, node.y+50, node.z, f\"({node.id})\", ha='center', fontsize=7)\n",
    "\n",
    "        energy = np.round(energy, 2)\n",
    "        ax.scatter(normal_nodes['x']    , normal_nodes['y']       , normal_nodes['z']   , marker=\"o\",color='purple' , edgecolors='k', label = \"Node\")\n",
    "        ax.scatter(orphan_nodes['x']    , orphan_nodes['y']       , orphan_nodes['z']   , marker=\"o\",color='c'      , edgecolors='k', label = \"Orphan Node\")\n",
    "        ax.scatter(CH_nodes['x']        , CH_nodes['y']           , CH_nodes['z']       , marker=\"o\",color=\"lime\"   , edgecolors='k', label = \"Cluster Head\")\n",
    "        ax.scatter(idle_nodes['x']      , idle_nodes['y']         , idle_nodes['z']     , marker=\"o\",color='yellow'      , edgecolors='k', label=\"Idle Node\")\n",
    "        ax.scatter(dead_nodes['x']      , dead_nodes['y']         , dead_nodes['z']     , marker=\"x\",color='r'      , label=\"Dead Node\")\n",
    "        ax.scatter(BS_node['x']         , BS_node['y']            , BS_node['z']        , marker=\"s\",color=\"b\"      , edgecolors='k', label=\"Base station\", s=50)\n",
    "\n",
    "        font = {\n",
    "                'color':  'black',\n",
    "                'weight': 'bold'\n",
    "                }\n",
    "\n",
    "        if self.mode == \"Q-Learning\":\n",
    "            for index_path in range(len(self.multihop_path)-1):\n",
    "                print(f\"{index_path} | Path : {len(self.multihop_path)} | Node : {len(self.nodes)}\")\n",
    "                start_x = self.nodes[self.multihop_path[index_path]].x\n",
    "                start_y = self.nodes[self.multihop_path[index_path]].y\n",
    "                start_z = self.nodes[self.multihop_path[index_path]].z\n",
    "                end_x = self.nodes[self.multihop_path[index_path+1]].x\n",
    "                end_y = self.nodes[self.multihop_path[index_path+1]].y\n",
    "                end_z = self.nodes[self.multihop_path[index_path+1]].z\n",
    "\n",
    "                # Compute the direction (vector) from start to end\n",
    "                dx = end_x - start_x\n",
    "                dy = end_y - start_y\n",
    "                dz = end_z - start_z\n",
    "                ax.quiver(start_x, start_y, start_z, dx, dy, dz, color='k')\n",
    "                \n",
    "        if ((self.mode == \"DECKS\") or (self.mode == \"K-Means\") or (self.mode == \"Q-Learning\")):\n",
    "            if count_CH != 0:\n",
    "                ax.scatter(self.centroids[:,0]  , self.centroids[:,1]     , marker=\"o\",color=\"y\"      , edgecolors='k', label=\"Centroid\")\n",
    "            ax.set_title(f'Round : {simulation_round} | E : {energy} | CH : {count_CH} | Opt k : {self.optimal_k}', fontdict=font)\n",
    "        else:\n",
    "            ax.set_title(f'Round : {simulation_round} | E : {energy} | CH : {count_CH}', fontdict=font)\n",
    "        \n",
    "        ax.set_title(f'Round : {simulation_round+1} | E : {energy} | CH : {count_CH}', fontdict=font)\n",
    "        ax.set_xlabel('Length (m)')\n",
    "        ax.set_ylabel('Width (m)')\n",
    "        ax.set_zlabel('Depth (m)')\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "              fancybox=True, shadow=True, ncol=3, markerscale=1, fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def multiHopRouting(self, node):\n",
    "        # Creatubg ab Adjacency Matrix for Q-Learning\n",
    "        if ((node.alive) and (node.energy>0)):\n",
    "            G = nx.Graph()\n",
    "            data = [[], [], [], []]\n",
    "            for nodeA in self.nodes:\n",
    "                for nodeB in self.nodes:\n",
    "                    distances = self.euclidean_distance(\n",
    "                        np.array([nodeA.x, nodeA.y, nodeA.z]), \n",
    "                        np.array([nodeB.x, nodeB.y, nodeB.z])\n",
    "                    )       \n",
    "                    if (\n",
    "                        (nodeA.energy > 0) and \n",
    "                        (nodeB.energy > 0) and \n",
    "                        (nodeA.alive) and \n",
    "                        (nodeB.alive) and \n",
    "                        (distances < d_max) and\n",
    "                        (nodeA.id != nodeB.id)\n",
    "                        \n",
    "                        ) :\n",
    "                        data[0].append(nodeA.id)\n",
    "                        data[1].append(nodeB.id)\n",
    "                        data[2].append(distances)\n",
    "                        data[3].append(1/nodeB.energy)\n",
    "                    # else:\n",
    "                    #     print(f\"{nodeA.id} - {nodeB.id} | {distances:.2f} m | alive ({nodeA.alive},{nodeB.alive}) | energy ({nodeA.energy:.2f},{nodeB.energy:.2f})\")\n",
    "\n",
    "            if not data[3]:\n",
    "                return [node.id]\n",
    "            dist_std, E_std = standardize_features(data[2], data[3])\n",
    "            # print(f\"[0] : {dist_std} | [1] : {E_std} | {dist_std+E_std}\")\n",
    "            std_data = E_std + dist_std\n",
    "            data[2] = std_data.tolist()\n",
    "\n",
    "            for i in range(len(data[0])):\n",
    "                G.add_edge(data[0][i], data[1][i], weight=round(data[2][i], 3))\n",
    "                        \n",
    "            Q_learning = multiHop(G)\n",
    "            paths, td = Q_learning.q_learning(start_state=node.id, aim_state = 0, num_epoch=self.QL_params['EPOCH'], gamma=self.QL_params['GAMMA'], epsilon=self.QL_params['EPSILON'], alpha=self.QL_params['ALPHA'])\n",
    "            # if len(paths) <= 1:\n",
    "            #     nx.draw(G, with_labels = True)\n",
    "            #     plt.show()\n",
    "\n",
    "        else:\n",
    "            print(f\"Not eligible for multi hop : {node.id}\")\n",
    "            paths = [node.id]\n",
    "        return paths\n",
    "    \n",
    "    def euclidean_distance(self, nodeA, nodeB):\n",
    "        return np.sqrt(np.sum((nodeA - nodeB)**2))\n",
    "        \n",
    "    def Nc(self, which_cluster):\n",
    "        count = 0\n",
    "        for node in self.nodes:\n",
    "            if node.which_cluster == which_cluster:\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    def LEACH(self, round_number):\n",
    "        for node in self.nodes:\n",
    "            d_CH_BS = self.euclidean_distance(np.array([node.x, node.y, node.z]), np.array(BS))\n",
    "            status = (\n",
    "                (node.energy > 0) and \n",
    "                (node.alive == True) and \n",
    "                (node.eligible_round == 0) \n",
    "            )\n",
    "            threshold = random.uniform(0, 1) < p/(1-p * (round_number % (1/p)))\n",
    "            # print(f\"s: {status} | thresh : {threshold} | over distance : {d_CH_BS < d_max}\")\n",
    "            if ((status) and (threshold)):\n",
    "                node.CH = True\n",
    "                node.which_cluster = node.id\n",
    "                node.eligible_round = 1/p\n",
    "    \n",
    "    def kmeans_plusplus(self, X, k):\n",
    "        centroids = []\n",
    "        centroids.append(X[np.random.randint(X.shape[0])])\n",
    "\n",
    "        for _ in range(1, k):\n",
    "            distances = np.array([min([np.linalg.norm(x - c) for c in centroids]) for x in X])\n",
    "            probabilities = distances / distances.sum()\n",
    "            cumulative_probabilities = probabilities.cumsum()\n",
    "            r = np.random.rand()\n",
    "            i = 0\n",
    "            for j, p in enumerate(cumulative_probabilities):\n",
    "                if r < p:\n",
    "                    i = j\n",
    "                    break\n",
    "            centroids.append(X[i])\n",
    "\n",
    "        return np.array(centroids)\n",
    "\n",
    "    def kmeans(self, X, k, iteration=100):\n",
    "        # Memilih random k centroid sebagai nilai awal\n",
    "        centroids = self.kmeans_plusplus(X, k)\n",
    "\n",
    "        for i in range(iteration):\n",
    "            while len(centroids) == 0:\n",
    "                centroids = self.kmeans_plusplus(X, k)\n",
    "            try:\n",
    "                distances = np.linalg.norm(X[:, None, :] - centroids, axis=2)\n",
    "            except :\n",
    "                print(f\"C : {centroids}\")\n",
    "            labels = np.argmin(distances, axis=1)\n",
    "            new_centroids = []\n",
    "            for j in range(k):\n",
    "                cluster_points = X[labels == j]\n",
    "                if len(cluster_points) > 0:\n",
    "                    new_centroids.append(cluster_points.mean(axis=0))\n",
    "                else:\n",
    "                    # Handle the case where the cluster is empty\n",
    "                    # You can choose to reassign a random point or some other strategy\n",
    "                    new_centroids.append(X[np.random.choice(len(X))])\n",
    "            \n",
    "            centroids = np.array(new_centroids)\n",
    "\n",
    "        return centroids, labels\n",
    "    \n",
    "    def kmeans_LEACH(self):                    \n",
    "        X, id = [], []\n",
    "        for node in self.nodes:\n",
    "            if ((node.id != 0) and (node.alive) and (node.energy > 0)) :\n",
    "                X.append([node.x, node.y, node.z])\n",
    "                id.append(node.id)\n",
    "\n",
    "        X = np.array(X)\n",
    "        if len (X) != 0 :\n",
    "            elbow = []\n",
    "            max_k = 15  # Maximum number of clusters to try\n",
    "            for k in range(1, max_k + 1):\n",
    "                centroids, labels = self.kmeans(X, k)\n",
    "                error = np.sum((X - centroids[labels])**2)\n",
    "                elbow.append(error)\n",
    "\n",
    "            # Calculate the change in distortions and find the elbow point\n",
    "            elbow = np.array(elbow)\n",
    "            elbow_diff = np.diff(elbow, prepend=elbow[0])\n",
    "            acceleration = np.diff(elbow_diff, prepend=elbow_diff[0])\n",
    "            self.optimal_k = np.argmax(acceleration)\n",
    "            self.centroids, labels = self.kmeans(X, self.optimal_k)\n",
    "\n",
    "            ch_id = []\n",
    "            for ch in self.centroids:\n",
    "                distances = [[], []]\n",
    "                for node in self.nodes:\n",
    "                    if ((node.id != 0) and (node.energy > 0) and (node.alive)):\n",
    "                        X = np.array([node.x, node.y, node.z])\n",
    "                        CH = np.array([ch[0], ch[1], ch[2]])\n",
    "                        distances[0].append(self.euclidean_distance(X, CH))\n",
    "                        distances[1].append(node.id)\n",
    "\n",
    "                ch_id.append(distances[1][np.argmin(distances[0])])\n",
    "\n",
    "            for node in self.nodes:\n",
    "                if node.id != 0:\n",
    "                    for id in ch_id:\n",
    "                        if node.id == id:\n",
    "                            node.CH = True\n",
    "                            node.which_cluster = id\n",
    "\n",
    "    def proposedMethod_CHSelection(self):                    \n",
    "        X, id = [], []\n",
    "        for node in self.nodes:\n",
    "            if ((node.id != 0) and (node.alive) and (node.energy > 0)) :\n",
    "                X.append([node.x, node.y, node.z])\n",
    "                id.append(node.id)\n",
    "\n",
    "        X = np.array(X)\n",
    "        if len (X) != 0 :\n",
    "            elbow = []\n",
    "            max_k = 15  # Maximum number of clusters to try\n",
    "            for k in range(1, max_k + 1):\n",
    "                centroids, labels = self.kmeans(X, k)\n",
    "                error = np.sum((X - centroids[labels])**2)\n",
    "                elbow.append(error)\n",
    "\n",
    "            # Calculate the change in distortions and find the elbow point\n",
    "            elbow = np.array(elbow)\n",
    "            elbow_diff = np.diff(elbow, prepend=elbow[0])\n",
    "            acceleration = np.diff(elbow_diff, prepend=elbow_diff[0])\n",
    "            self.optimal_k = np.argmax(acceleration)\n",
    "            self.centroids, labels = self.kmeans(X, self.optimal_k)\n",
    "\n",
    "            ch_id = []\n",
    "            for ch in self.centroids:\n",
    "                distances = [[], [], []]\n",
    "                for node in self.nodes:\n",
    "                    if ((node.id != 0) and (node.energy > 0) and (node.alive)):\n",
    "                        X = np.array([node.x, node.y, node.z])\n",
    "                        CH = np.array([ch[0], ch[1], ch[2]])\n",
    "                        distances[0].append(self.euclidean_distance(X, CH))\n",
    "                        distances[1].append(node.id)\n",
    "                        distances[2].append(1/node.energy)\n",
    "                        \n",
    "                data = np.array([distances[0], distances[2]])\n",
    "                scaler = StandardScaler()\n",
    "                standardized_data = scaler.fit_transform(data)\n",
    "                ch_id.append(distances[1][np.argmin(standardized_data[0] + standardized_data[1])])\n",
    "\n",
    "            print(ch_id)\n",
    "            for node in self.nodes:\n",
    "                if node.id != 0:\n",
    "                    for id in ch_id:\n",
    "                        if node.id == id:\n",
    "                            node.CH = True\n",
    "                            node.which_cluster = id\n",
    "\n",
    "    def DECKS_LEACH(self, DECKS_threshold):                    \n",
    "        X, id = [], []\n",
    "        for node in self.nodes:\n",
    "            if ((node.id != 0) and (node.alive) and (node.energy > 0)) :\n",
    "                X.append([node.x, node.y, node.z])\n",
    "                id.append(node.id)\n",
    "\n",
    "        X = np.array(X)\n",
    "        if len (X) != 0 :\n",
    "            elbow = []\n",
    "            max_k = 15  # Maximum number of clusters to try\n",
    "            for k in range(1, max_k + 1):\n",
    "                centroids, labels = self.kmeans(X, k)\n",
    "                error = np.sum((X - centroids[labels])**2)\n",
    "                elbow.append(error)\n",
    "\n",
    "            # Calculate the change in distortions and find the elbow point\n",
    "            elbow = np.array(elbow)\n",
    "            elbow_diff = np.diff(elbow, prepend=elbow[0])\n",
    "            acceleration = np.diff(elbow_diff, prepend=elbow_diff[0])\n",
    "            self.optimal_k = np.argmax(acceleration)\n",
    "            self.centroids, labels = self.kmeans(X, self.optimal_k)\n",
    "\n",
    "            labels = np.array(labels)\n",
    "            number_of_clusters = np.unique(labels)\n",
    "\n",
    "            for cluster in number_of_clusters:\n",
    "                count = 0\n",
    "                within_cluster = []\n",
    "                for label in labels:\n",
    "                    if label == cluster:\n",
    "                        within_cluster.append(self.nodes[count])\n",
    "                    count += 1\n",
    "\n",
    "                nearest_distance = []\n",
    "                for node_i in within_cluster:\n",
    "                    sum_euclidian = 0\n",
    "                    for node_j in within_cluster:\n",
    "                        if ((node_i != node_j) and (node_i.energy > DECKS_threshold) and (node_j.energy > 0)):\n",
    "                            sum_euclidian += self.euclidean_distance(np.array([node_i.x, node_i.y, node_i.z]), np.array([node_j.x, node_j.y, node_j.z]))\n",
    "                    nearest_distance.append(sum_euclidian)\n",
    "\n",
    "                nearest_distance = np.array(nearest_distance)\n",
    "                CH_id = within_cluster[np.argmin(nearest_distance)]\n",
    "                for node in self.nodes:\n",
    "                  if node.id == CH_id.id :\n",
    "                      node.CH = True\n",
    "                      node.which_cluster = node.id\n",
    "                \n",
    "    \n",
    "    def CH_selection(self, round_number):\n",
    "        for node in self.nodes:\n",
    "            node.reset()\n",
    "        \n",
    "        if self.mode == \"LEACH\":\n",
    "            self.LEACH(round_number)\n",
    "        elif self.mode == \"Q-Learning\":\n",
    "            self.proposedMethod_CHSelection()\n",
    "        elif self.mode == \"K-Means\":\n",
    "            self.kmeans_LEACH()\n",
    "        elif self.mode == \"DECKS\":\n",
    "            self.DECKS_LEACH(DECKS_threshold)\n",
    "\n",
    "        CHs = [node for node in self.nodes if node.CH]\n",
    "        node_alive = [node for node in self.nodes if  ((node.energy > 0) and (node.alive == True) and (node.id != 0) and (node.CH != True) and (node.has_data == 1))]\n",
    "        has_data = bernoulli.rvs(bernoulli_probability, size=len(node_alive))\n",
    "\n",
    "        count = 0\n",
    "        for node in self.nodes:\n",
    "            status = ((node.energy > 0) and (node.alive == True) and (node.id != 0) and (node.CH != True))\n",
    "            if status:\n",
    "                if has_data[count] == 0:\n",
    "                    node.has_data = False\n",
    "                count += 1\n",
    "        \n",
    "        for node in self.nodes:\n",
    "            status = ((node.energy > 0) and (node.alive == True) and (node.id != 0) and (node.CH != True))\n",
    "            if len(CHs):\n",
    "                distances = [[], []]\n",
    "                if status:\n",
    "                    for CH in CHs:\n",
    "                        Ch_coor = [CH.x, CH.y, CH.z]\n",
    "                        distances[0].append(\n",
    "                            self.euclidean_distance(np.array([node.x, node.y, node.z]), np.array(Ch_coor))\n",
    "                        )\n",
    "                        distances[1].append(CH.which_cluster)\n",
    "                    if distances[0][np.argmin(distances[0])] > d_max:\n",
    "                        node.which_cluster = 0\n",
    "                    else:\n",
    "                        node.which_cluster = distances[1][np.argmin(distances[0])]\n",
    "            if len(CHs) <= 0:\n",
    "                # Jika tidak ada yang terpilih sebagai CH, maka node akan diam\n",
    "                if node.id != 0:\n",
    "                    node.which_cluster = 0\n",
    "            count += 1\n",
    "            \n",
    "        if round_number % self.showPlotIteration == 0:\n",
    "            self.showNetwork(round_number)\n",
    "            \n",
    "    def SetupPhase(self, simulation_round):\n",
    "        # CH Selection and Advertisement Energy Dissipation and Creating TDMA Schedule\n",
    "        # Node Join Energy Dissipation and join TDMA Schedule\n",
    "        self.CH_selection(simulation_round)\n",
    "        CHs = [node for node in self.nodes if node.CH]\n",
    "        energy = 0\n",
    "\n",
    "        for node in self.nodes:\n",
    "            status = (\n",
    "                (node.energy > 0) and \n",
    "                (node.alive) and \n",
    "                (node.id != 0) and \n",
    "                (node.which_cluster != 0) and\n",
    "                (node.has_data)\n",
    "            )\n",
    "            if status:\n",
    "                if node.CH:\n",
    "                    Nc = self.Nc(node.which_cluster)\n",
    "                    d_CH_BS = self.euclidean_distance(np.array([node.x, node.y, node.z]), np.array(BS))\n",
    "                    energy_dissipated = node.energyAdvertisement() + node.energySelection(d_CH_BS, len(CHs)/N) + node.energy_contention_TDMA_CH(Nc)\n",
    "                    node.energy = node.energy - energy_dissipated\n",
    "                    energy += energy_dissipated\n",
    "                else:\n",
    "                    for CH in CHs:\n",
    "                        if node.which_cluster == CH.which_cluster :\n",
    "                            Nc = self.Nc(node.which_cluster)\n",
    "                            d_CH_Node = self.euclidean_distance(np.array([node.x, node.y, node.z]), np.array([CH.x, CH.y, CH.z]))\n",
    "                            energy_dissipated = node.energy_contention_TDMA_Node(Nc, d_CH_Node) + node.energyJoin(len(CHs)/N)\n",
    "                            node.energy = node.energy - energy_dissipated\n",
    "                            energy += energy_dissipated\n",
    "            \n",
    "\n",
    "            if ((node.energy > 0) and (node.which_cluster == 0)):\n",
    "                # If node is not in cluster, it become idle\n",
    "                node.energy -= node.energyIdle()\n",
    "                energy += node.energyIdle()\n",
    "                \n",
    "            if node.energy < 0:\n",
    "                if self.showInfo:\n",
    "                    print(f\"\\tNode dead found during Setup phase at round - {simulation_round} \\nId-{node.id} | E : {node.energy} | CH : {node.CH} | Cluster : {node.which_cluster}\")\n",
    "                node.alive = False\n",
    "    \n",
    "        self.setupPhaseEnergy.append(energy)\n",
    "        \n",
    "    def SteadyStatePhase(self, simulation_round):\n",
    "        CHs = []\n",
    "        energy_total = 0\n",
    "        node_alive = 0\n",
    "        node_failure = 0\n",
    "        energy = 0\n",
    "        total_data = 0\n",
    "        success_delivered = 0\n",
    "\n",
    "        for node in self.nodes:\n",
    "            status = (\n",
    "                (node.energy > 0) and \n",
    "                (node.alive == True) and \n",
    "                (node.id != 0) and \n",
    "                (node.which_cluster != 0)\n",
    "            )\n",
    "            if status:\n",
    "                if node.CH:\n",
    "                    CHs.append(node)\n",
    "        \n",
    "\n",
    "        # Transmission process\n",
    "        for node in self.nodes:\n",
    "            if ((node.energy > 0) and (node.alive == True) and(node.id != 0) and (node.which_cluster != 0) and (node.has_data == 1)):\n",
    "                if node.CH == True:\n",
    "                    Nc = self.Nc(node.which_cluster)\n",
    "                    d_CH_BS = self.euclidean_distance(np.array([node.x, node.y, node.z]), np.array(BS))\n",
    "                    node.energy = node.energy - node.energyFrame_CH(Nc, d_CH_BS)\n",
    "                    energy += node.energyFrame_CH(Nc, d_CH_BS)\n",
    "\n",
    "                    if d_CH_BS < d_max:\n",
    "                        success_delivered += kc + kd * Nc\n",
    "                        \n",
    "                    total_data += kc + kd * Nc\n",
    "                else:\n",
    "                    for CH in CHs:\n",
    "                        if node.which_cluster == CH.which_cluster :\n",
    "                            d_CH_Node = self.euclidean_distance(np.array([node.x, node.y, node.z]), np.array([CH.x, CH.y, CH.z]))\n",
    "                            node.energy = node.energy - node.energyFrame_Node(d_CH_Node)\n",
    "                            energy += node.energyFrame_Node(d_CH_Node)\n",
    "                            \n",
    "\n",
    "            if ((node.energy > 0) and (node.alive == True) and (node.id != 0) and (node.which_cluster == 0) and (node.has_data == 1)):\n",
    "                total_data += kd\n",
    "                if self.mode != \"Q-Learning\":\n",
    "                    node_failure += 1\n",
    "                    node.energy -= node.energyIdle()\n",
    "                    energy += node.energyIdle()\n",
    "                else:\n",
    "                    self.multihop_path = self.multiHopRouting(node)\n",
    "                    print(f\"Round : {simulation_round} | PATH : {self.multihop_path} | node.energy : {node.energy}\")\n",
    "                    if len(self.multihop_path) > 1:\n",
    "                        for i in range(0, len(self.multihop_path)-1):\n",
    "                            if node.energy > 0:\n",
    "                                nodeA, nodeB = self.nodes[self.multihop_path[i]], self.nodes[self.multihop_path[i+1]]\n",
    "                                d_CH_Node = self.euclidean_distance(np.array([nodeA.x, nodeA.y]), np.array([nodeB.x, nodeB.y]))\n",
    "                                # print(f\"    path data from {nodeA.id} to {nodeB.id} d : {d_CH_Node:.2f}\")\n",
    "                                node.energy = node.energy - node.energyHop(d_CH_Node)\n",
    "                                energy += node.energyHop(d_CH_Node)\n",
    "                        success_delivered += kd\n",
    "                    else:\n",
    "                        node.energy -= node.energyIdle()\n",
    "                        energy += node.energyIdle()\n",
    "                    \n",
    "                    if ((len(self.multihop_path) > 2) and (simulation_round % self.showPlotIteration == 0)):\n",
    "                        self.show_path = self.multihop_path\n",
    "                        self.showNetwork(simulation_round)\n",
    "            # else:\n",
    "            #     stat = ((node.energy > 0) and (node.alive == True) and(node.id != 0) and (node.which_cluster == 0) and (node.has_data == 1))\n",
    "            #     # print(\n",
    "            #     #     f\"Stat : {stat}\\nE : {(node.energy > 0)} | A: {(node.alive == True)} \\nId : {(node.id != 0)} | C : {(node.which_cluster == 0)} | Has data : {(node.has_data == 1)}\\n\\n\"\n",
    "            #     # )\n",
    "            node.eligible_round -= 1\n",
    "            if node.eligible_round < 0:\n",
    "                node.eligible_round = 0\n",
    "\n",
    "            if node.energy < 0:\n",
    "                node.alive = False\n",
    "            \n",
    "            if node.alive:\n",
    "                node_alive += 1\n",
    "                energy_total += node.energy\n",
    "\n",
    "        if total_data > 0:\n",
    "            pdr = success_delivered/total_data\n",
    "        else:\n",
    "            pdr = 0\n",
    "        \n",
    "        self.data_sent += success_delivered\n",
    "\n",
    "        self.total_packet_sent.append(self.data_sent)\n",
    "        self.PDR.append(pdr)\n",
    "        self.steadyPhaseEnergy.append(energy)\n",
    "        self.node_failure.append(node_failure)\n",
    "        self.alive_data.append(node_alive)\n",
    "        self.energy_data.append(energy_total)\n",
    "\n",
    "    def startSimulation(self, rounds):\n",
    "        #self.showNetwork(0)\n",
    "        print(f\"Mode : {self.mode}\")\n",
    "        for simulation_round in range(0, rounds+1):\n",
    "            self.SetupPhase(simulation_round)\n",
    "            # print(f\"Round : {simulation_round}\")\n",
    "            self.SteadyStatePhase(simulation_round)\n",
    "        self.showResult(5)\n",
    "\n",
    "        params = {\n",
    "            'Alive' : self.alive_data,\n",
    "            'Energy Residual' : self.energy_data,\n",
    "            'Node Failure' : self.node_failure,\n",
    "            'PDR' : self.PDR,\n",
    "            'Total Packet Sent' : self.total_packet_sent,\n",
    "            'Energy Setup Consumed' : self.setupPhaseEnergy,\n",
    "            'Energy Steady Consumed' : self.steadyPhaseEnergy,\n",
    "        }\n",
    "        return params\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QL_params = {\n",
    "                'EPOCH'   : 1000,\n",
    "                'EPSILON' : 0.1,\n",
    "                'GAMMA'   : 0.8,\n",
    "                'ALPHA'   : 0.2\n",
    "            }\n",
    "node_Q_Learning    = createNetworks()\n",
    "Q_Learning = networkEnvironment(node_Q_Learning, \"Q-Learning\", True, 201, QL_params)\n",
    "Q_Learning_params = Q_Learning.startSimulation(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QL_params = {\n",
    "                'EPOCH'   : 1000,\n",
    "                'EPSILON' : 0.1,\n",
    "                'GAMMA'   : 0.1,\n",
    "                'ALPHA'   : 0.1\n",
    "            }\n",
    "node_LEACH    = createNetworks()\n",
    "LEACH = networkEnvironment(node_LEACH, \"LEACH\", True, 201, QL_params)\n",
    "LEACH_params = LEACH.startSimulation(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = len(LEACH_params.keys())\n",
    "fig, ax = plt.subplots(params, 1, figsize=(8, 32), dpi=250)\n",
    "\n",
    "markers = ['o', 's', '^', 'v']\n",
    "colors = ['g', 'r', 'b', 'y']\n",
    "\n",
    "count = 0\n",
    "for param in LEACH_params.keys():\n",
    "    rounds = [i for i in range(len(LEACH_params['Alive']))]\n",
    "    ax[count].plot(rounds, LEACH_params[param])\n",
    "    ax[count].plot(rounds, Q_Learning_params[param])\n",
    "    ax[count].scatter(rounds, LEACH_params[param]             , edgecolors='k' , label=\"Random\")\n",
    "    ax[count].scatter(rounds, Q_Learning_params[param]      , edgecolors='k' , label=\"Proposed Method\")\n",
    "\n",
    "    ax[count].set_title(param, fontsize=12)\n",
    "    plt.legend()\n",
    "    count += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1000\n",
    "gamma = 0.5\n",
    "epsilon_start = 0.8\n",
    "epsilon_end = 0.9\n",
    "file_path = f'TRIAL_II_EPOCH_{epoch}_GAMMA_{gamma}_EPSILON_[{epsilon_start}-{epsilon_end}]_QL_tuning.xlsx'\n",
    "count = 0\n",
    "\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    df_tuning_result = pd.read_excel(file_path)\n",
    "    for epsilon in [i for i in range(int(epsilon_start * 10), int(epsilon_end * 10)+1)]:\n",
    "        epsilon = epsilon * 0.1\n",
    "        for alpha in range(1, 11):\n",
    "            start_time = time.time()\n",
    "            alpha = alpha * 0.1\n",
    "            QL_params = {\n",
    "                'EPOCH'   : epoch,\n",
    "                'EPSILON' : epsilon,\n",
    "                'GAMMA'   : gamma,\n",
    "                'ALPHA'   : alpha\n",
    "            }\n",
    "            start_time         = time.time()\n",
    "            node_Q_Learning    = createNetworks()\n",
    "            Q_Learning = networkEnvironment(node_Q_Learning, \"Q-Learning\", False, 201, QL_params)\n",
    "            Q_Learning_params = Q_Learning.startSimulation(200)\n",
    "            energy            = sum(Q_Learning_params['Energy Residual'])\n",
    "\n",
    "            end_time = time.time()  \n",
    "            time_taken = end_time - start_time\n",
    "            print(f\"{time_taken:.2f} | {count} | epsilon : {epsilon} | alpha : {alpha} | gamma : {gamma} | E : {energy}\")\n",
    "            end_time = time.time()\n",
    "\n",
    "            result = {\n",
    "                'EPOCH'   : [epoch  ],\n",
    "                'EPSILON' : [epsilon],\n",
    "                'GAMMA'   : [gamma  ],\n",
    "                'ALPHA'   : [alpha  ],\n",
    "                'Energy Residual'  : [energy ]\n",
    "            }\n",
    "\n",
    "            result = pd.DataFrame(result)\n",
    "            df_tuning_result = pd.read_excel(file_path)\n",
    "            df_tuning_result = pd.concat(\n",
    "                [df_tuning_result, result], \n",
    "                ignore_index=True\n",
    "            )\n",
    "            print(df_tuning_result.tail(5))\n",
    "            df_tuning_result.to_excel(file_path, index=False)\n",
    "            count += 1\n",
    "else:\n",
    "    df_tuning_result = {\n",
    "        'EPOCH'   : [],\n",
    "        'EPSILON' : [],\n",
    "        'GAMMA'   : [],\n",
    "        'ALPHA'   : [],\n",
    "        'Energy Residual'  : []\n",
    "    }\n",
    "    df_tuning_result = pd.DataFrame(df_tuning_result)\n",
    "    df_tuning_result.to_excel(file_path, index=False)\n",
    "\n",
    "count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_sound(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
